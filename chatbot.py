import logging
from typing import List, Dict, Optional
from langchain.schema import HumanMessage, SystemMessage
from langchain.prompts import ChatPromptTemplate
from config import Config
from vector_store import VectorStore
from gemini_llm import GeminiLLM

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TuyenSinhBot:
    def __init__(self):
        self.vector_store = VectorStore()
        self.llm = None
        self.conversation_history = []
        if getattr(Config, "GEMINI_API_KEY", None):
            self.llm = GeminiLLM()
            self.llm_type = "gemini"
            logger.info("âœ… Gemini API key Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh thÃ nh cÃ´ng!")
        else:
            self.llm_type = None
            logger.warning(
                "KhÃ´ng cÃ³ Gemini API key. Bot sáº½ chá»‰ sá»­ dá»¥ng tÃ¬m kiáº¿m vector."
            )
        self.vector_store.build_vector_store()
        self.prompt_template = ChatPromptTemplate.from_messages(
            [
                ("system", Config.SYSTEM_PROMPT),
                (
                    "human",
                    """Dá»±a trÃªn thÃ´ng tin sau Ä‘Ã¢y, hÃ£y tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  há»¯u Ã­ch:\n\nThÃ´ng tin tham kháº£o:\n{context}\n\nCÃ¢u há»i: {question}\n\nLÆ°u Ã½: Náº¿u thÃ´ng tin khÃ´ng Ä‘á»§ Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c, hÃ£y nÃ³i rÃµ ráº±ng báº¡n khÃ´ng cÃ³ Ä‘á»§ thÃ´ng tin vÃ  Ä‘á» xuáº¥t ngÆ°á»i dÃ¹ng liÃªn há»‡ trá»±c tiáº¿p vá»›i trÆ°á»ng Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.""",
                ),
            ]
        )

    def get_relevant_context(self, question: str, k: int = 5, use_query_expansion: bool = True) -> str:
        results = self.vector_store.search(question, k=k, use_query_expansion=use_query_expansion)
        if not results:
            return "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u."
        context_parts = []
        for i, result in enumerate(results, 1):
            context_parts.append(
                f"ThÃ´ng tin {i} (tá»« {result['source']}):\n{result['content']}"
            )
        return "\n\n".join(context_parts)

    def generate_response(self, question: str, context: str) -> str:
        if not self.llm:
            return f"ThÃ´ng tin tÃ¬m Ä‘Æ°á»£c:\n\n{context}\n\nLÆ°u Ã½: Äá»ƒ cÃ³ cÃ¢u tráº£ lá»i chi tiáº¿t hÆ¡n, vui lÃ²ng cung cáº¥p Gemini API key."
        try:
            # Táº¡o prompt hoÃ n chá»‰nh bao gá»“m system prompt vÃ  cÃ¢u há»i
            full_prompt = f"""{Config.SYSTEM_PROMPT}

Dá»±a trÃªn thÃ´ng tin sau Ä‘Ã¢y, hÃ£y tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  há»¯u Ã­ch:

ThÃ´ng tin tham kháº£o:
{context}

CÃ¢u há»i: {question}

LÆ°u Ã½: Náº¿u thÃ´ng tin khÃ´ng Ä‘á»§ Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c, hÃ£y nÃ³i rÃµ ráº±ng báº¡n khÃ´ng cÃ³ Ä‘á»§ thÃ´ng tin vÃ  Ä‘á» xuáº¥t ngÆ°á»i dÃ¹ng liÃªn há»‡ trá»±c tiáº¿p vá»›i trÆ°á»ng Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t:"""
            
            logger.info(f"ğŸ“ Prompt gá»­i Ä‘áº¿n Gemini: {full_prompt[:200]}...")
            return self.llm.generate(full_prompt)
        except Exception as e:
            logger.error(f"Lá»—i khi táº¡o cÃ¢u tráº£ lá»i: {str(e)}")
            return f"Xin lá»—i, cÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ cÃ¢u há»i. ThÃ´ng tin tÃ¬m Ä‘Æ°á»£c:\n\n{context}"

    def chat(self, user_message: str, use_query_expansion: bool = True) -> Dict:
        try:
            logger.info(f"ğŸ‘¤ User há»i: {user_message}")
            self.conversation_history.append({"role": "user", "content": user_message})
            if len(self.conversation_history) > Config.MAX_HISTORY * 2:
                self.conversation_history = self.conversation_history[
                    -Config.MAX_HISTORY * 2 :
                ]
            context = self.get_relevant_context(user_message, use_query_expansion=use_query_expansion)
            response = self.generate_response(user_message, context)
            logger.info(f"ğŸ¤– Bot tráº£ lá»i: {response[:200]}...")
            self.conversation_history.append({"role": "assistant", "content": response})
            return {"response": response, "context_used": context, "success": True}
        except Exception as e:
            logger.error(f"âŒ Lá»—i khi xá»­ lÃ½ cÃ¢u há»i '{user_message}': {str(e)}")
            logger.error(f"Lá»—i trong quÃ¡ trÃ¬nh chat: {str(e)}")
            return {
                "response": "Xin lá»—i, cÃ³ lá»—i xáº£y ra. Vui lÃ²ng thá»­ láº¡i sau.",
                "context_used": "",
                "success": False,
                "error": str(e),
            }

    def get_conversation_history(self) -> List[Dict]:
        return self.conversation_history.copy()

    def clear_history(self):
        self.conversation_history = []

    def get_statistics(self) -> Dict:
        vector_stats = self.vector_store.get_statistics()
        return {
            "vector_store": vector_stats,
            "llm_available": self.llm is not None,
            "conversation_history_length": len(self.conversation_history),
            "model_name": "gemini" if self.llm else "None",
        }

    def suggest_questions(self) -> List[str]:
        return [
            "Chá»‰ tiÃªu tuyá»ƒn sinh nÄƒm 2025",
            "Äiá»ƒm chuáº©n cÃ¡c ngÃ nh nÄƒm 2023-2024 nhÆ° tháº¿ nÃ o?",
            "Quy cháº¿ tuyá»ƒn sinh nÄƒm 2025 cÃ³ gÃ¬ má»›i?",
            "CÃ¡c ngÃ nh Ä‘Ã o táº¡o cá»§a trÆ°á»ng ÄHQN gá»“m nhá»¯ng gÃ¬?",
            "Thá»i gian ná»™p há»“ sÆ¡ tuyá»ƒn sinh nÄƒm 2025?",
            "Äiá»u kiá»‡n xÃ©t tuyá»ƒn há»c báº¡ nhÆ° tháº¿ nÃ o?",
            "CÃ³ bao nhiÃªu phÆ°Æ¡ng thá»©c xÃ©t tuyá»ƒn?",
            "ThÃ´ng tin vá» há»c phÃ­ vÃ  chÃ­nh sÃ¡ch há»c bá»•ng?",
        ]


if __name__ == "__main__":
    # Test bot
    bot = TuyenSinhBot()

    test_questions = [
        "Chá»‰ tiÃªu tuyá»ƒn sinh 2025",
        "Äiá»ƒm chuáº©n nÄƒm 2023",
        "Quy cháº¿ tuyá»ƒn sinh",
    ]

    for question in test_questions:
        print(f"\n{'='*50}")
        print(f"CÃ¢u há»i: {question}")
        print(f"{'='*50}")

        result = bot.chat(question)
        print(f"Tráº£ lá»i: {result['response']}")
        print(f"ThÃ nh cÃ´ng: {result['success']}")
