import logging
import numpy as np
from typing import List, Dict, Tuple
from langchain_huggingface import HuggingFaceEmbeddings
from config import Config
import re

logger = logging.getLogger(__name__)


class QueryExpander:
    def __init__(self):
        """Kh·ªüi t·∫°o QueryExpander v·ªõi embedding model"""
        self.embeddings = HuggingFaceEmbeddings(
            model_name=Config.EMBEDDING_MODEL,
            model_kwargs={'device': 'cpu'}
        )
        
        # T·ª´ ƒëi·ªÉn t·ª´ ƒë·ªìng nghƒ©a ti·∫øng Vi·ªát cho tuy·ªÉn sinh
        self.synonyms = {
            'tuy·ªÉn sinh': ['x√©t tuy·ªÉn', 'nh·∫≠p h·ªçc', 'ƒëƒÉng k√Ω', 'thi tuy·ªÉn'],
            'ch·ªâ ti√™u': ['quota', 's·ªë l∆∞·ª£ng', 'ƒë·ªãnh m·ª©c', 'h·∫°n m·ª©c'],
            'ƒëi·ªÉm chu·∫©n': ['ƒëi·ªÉm s√†n', 'ƒëi·ªÉm tr√∫ng tuy·ªÉn', 'ƒëi·ªÉm ƒë·∫ßu v√†o'],
            'ng√†nh': ['chuy√™n ng√†nh', 'lƒ©nh v·ª±c', 'b·ªô m√¥n', 'khoa'],
            'tr∆∞·ªùng': ['ƒë·∫°i h·ªçc', 'h·ªçc vi·ªán', 'vi·ªán', 'c∆° s·ªü ƒë√†o t·∫°o'],
            'h·ªçc ph√≠': ['ph√≠ ƒë√†o t·∫°o', 'ti·ªÅn h·ªçc', 'chi ph√≠ h·ªçc t·∫≠p'],
            'th·ªùi gian': ['th·ªùi h·∫°n', 'k·ª≥ h·∫°n', 'deadline', 'h·∫°n ch√≥t'],
            'h·ªì s∆°': ['gi·∫•y t·ªù', 't√†i li·ªáu', 'vƒÉn b·∫£n', 'ch·ª©ng t·ª´'],
            'x√©t tuy·ªÉn': ['tuy·ªÉn sinh', 'nh·∫≠p h·ªçc', 'ƒëƒÉng k√Ω', 'thi tuy·ªÉn'],
            'quota': ['ch·ªâ ti√™u', 's·ªë l∆∞·ª£ng', 'ƒë·ªãnh m·ª©c', 'h·∫°n m·ª©c'],
            'ƒëi·ªÉm s√†n': ['ƒëi·ªÉm chu·∫©n', 'ƒëi·ªÉm tr√∫ng tuy·ªÉn', 'ƒëi·ªÉm ƒë·∫ßu v√†o'],
            'chuy√™n ng√†nh': ['ng√†nh', 'lƒ©nh v·ª±c', 'b·ªô m√¥n', 'khoa'],
            'ƒë·∫°i h·ªçc': ['tr∆∞·ªùng', 'h·ªçc vi·ªán', 'vi·ªán', 'c∆° s·ªü ƒë√†o t·∫°o'],
            'ph√≠ ƒë√†o t·∫°o': ['h·ªçc ph√≠', 'ti·ªÅn h·ªçc', 'chi ph√≠ h·ªçc t·∫≠p'],
            'th·ªùi h·∫°n': ['th·ªùi gian', 'k·ª≥ h·∫°n', 'deadline', 'h·∫°n ch√≥t'],
            'gi·∫•y t·ªù': ['h·ªì s∆°', 't√†i li·ªáu', 'vƒÉn b·∫£n', 'ch·ª©ng t·ª´']
        }
        
        # C√°c t·ª´ kh√≥a quan tr·ªçng trong tuy·ªÉn sinh
        self.important_keywords = [
            'tuy·ªÉn sinh', 'ch·ªâ ti√™u', 'ƒëi·ªÉm chu·∫©n', 'ng√†nh', 'tr∆∞·ªùng',
            'h·ªçc ph√≠', 'th·ªùi gian', 'h·ªì s∆°', 'x√©t tuy·ªÉn', 'quota',
            'ƒëi·ªÉm s√†n', 'chuy√™n ng√†nh', 'ƒë·∫°i h·ªçc', 'ph√≠ ƒë√†o t·∫°o',
            'th·ªùi h·∫°n', 'gi·∫•y t·ªù', '2025', '2024', '2023'
        ]

    def expand_with_synonyms(self, query: str) -> List[str]:
        """M·ªü r·ªông truy v·∫•n b·∫±ng t·ª´ ƒë·ªìng nghƒ©a"""
        expanded_queries = [query]
        
        # T√°ch t·ª´ trong c√¢u h·ªèi
        words = re.findall(r'\b\w+\b', query.lower())
        
        for word in words:
            if word in self.synonyms:
                synonyms = self.synonyms[word]
                for synonym in synonyms:
                    # Thay th·∫ø t·ª´ g·ªëc b·∫±ng t·ª´ ƒë·ªìng nghƒ©a
                    new_query = re.sub(
                        r'\b' + re.escape(word) + r'\b',
                        synonym,
                        query,
                        flags=re.IGNORECASE
                    )
                    if new_query != query:
                        expanded_queries.append(new_query)
        
        # Lo·∫°i b·ªè c√°c truy v·∫•n tr√πng l·∫∑p
        expanded_queries = list(set(expanded_queries))
        
        logger.info(f"üîç M·ªü r·ªông truy v·∫•n '{query}' th√†nh {len(expanded_queries)} phi√™n b·∫£n")
        for i, exp_query in enumerate(expanded_queries[:3], 1):
            logger.info(f"   {i}. {exp_query}")
        
        return expanded_queries

    def expand_with_embeddings(self, query: str, context_queries: List[str] = None) -> str:
        """M·ªü r·ªông truy v·∫•n b·∫±ng embedding trung b√¨nh"""
        try:
            # T·∫°o embedding cho truy v·∫•n g·ªëc
            query_embedding = self.embeddings.embed_query(query)
            
            # N·∫øu c√≥ context queries, t√≠nh embedding trung b√¨nh
            if context_queries:
                context_embeddings = []
                for ctx_query in context_queries:
                    try:
                        ctx_emb = self.embeddings.embed_query(ctx_query)
                        context_embeddings.append(ctx_emb)
                    except Exception as e:
                        logger.warning(f"Kh√¥ng th·ªÉ t·∫°o embedding cho: {ctx_query} - {e}")
                
                if context_embeddings:
                    # T√≠nh embedding trung b√¨nh
                    avg_embedding = np.mean(context_embeddings, axis=0)
                    
                    # K·∫øt h·ª£p v·ªõi embedding g·ªëc (weighted average)
                    combined_embedding = 0.7 * np.array(query_embedding) + 0.3 * avg_embedding
                    
                    logger.info(f"üß† K·∫øt h·ª£p embedding t·ª´ {len(context_embeddings)} context queries")
                    return query  # Tr·∫£ v·ªÅ query g·ªëc, embedding ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t
            
            return query
            
        except Exception as e:
            logger.error(f"L·ªói khi t·∫°o embedding cho query: {e}")
            return query

    def extract_keywords(self, query: str) -> List[str]:
        """Tr√≠ch xu·∫•t t·ª´ kh√≥a quan tr·ªçng t·ª´ truy v·∫•n"""
        words = re.findall(r'\b\w+\b', query.lower())
        keywords = [word for word in words if word in self.important_keywords]
        
        logger.info(f"üîë Tr√≠ch xu·∫•t keywords t·ª´ '{query}': {keywords}")
        return keywords

    def create_context_queries(self, original_query: str) -> List[str]:
        """T·∫°o c√°c truy v·∫•n context d·ª±a tr√™n t·ª´ kh√≥a"""
        keywords = self.extract_keywords(original_query)
        context_queries = []
        
        # T·∫°o c√°c truy v·∫•n context b·∫±ng c√°ch k·∫øt h·ª£p t·ª´ kh√≥a
        for i, keyword1 in enumerate(keywords):
            for keyword2 in keywords[i+1:]:
                context_query = f"{keyword1} {keyword2}"
                context_queries.append(context_query)
        
        # Th√™m c√°c truy v·∫•n ƒë∆°n t·ª´ kh√≥a quan tr·ªçng
        for keyword in keywords:
            if keyword not in [q.split()[0] for q in context_queries]:
                context_queries.append(keyword)
        
        logger.info(f"üìù T·∫°o {len(context_queries)} context queries t·ª´ {len(keywords)} keywords")
        return context_queries[:5]  # Gi·ªõi h·∫°n 5 context queries

    def expand_query(self, query: str, method: str = "combined") -> List[str]:
        """M·ªü r·ªông truy v·∫•n theo ph∆∞∆°ng ph√°p ƒë∆∞·ª£c ch·ªçn"""
        if method == "synonyms":
            return self.expand_with_synonyms(query)
        elif method == "embeddings":
            context_queries = self.create_context_queries(query)
            expanded_query = self.expand_with_embeddings(query, context_queries)
            return [expanded_query]
        elif method == "combined":
            # K·∫øt h·ª£p c·∫£ hai ph∆∞∆°ng ph√°p
            synonym_queries = self.expand_with_synonyms(query)
            context_queries = self.create_context_queries(query)
            
            # Th√™m context queries v√†o danh s√°ch
            all_queries = synonym_queries + context_queries
            
            # Lo·∫°i b·ªè tr√πng l·∫∑p v√† gi·ªõi h·∫°n s·ªë l∆∞·ª£ng
            unique_queries = list(set(all_queries))
            return unique_queries[:8]  # Gi·ªõi h·∫°n 8 truy v·∫•n
        else:
            return [query]

    def get_query_variations(self, query: str) -> Dict[str, List[str]]:
        """L·∫•y t·∫•t c·∫£ c√°c bi·∫øn th·ªÉ c·ªßa truy v·∫•n"""
        return {
            'original': [query],
            'synonyms': self.expand_with_synonyms(query),
            'context': self.create_context_queries(query),
            'combined': self.expand_query(query, "combined")
        }


if __name__ == "__main__":
    # Test QueryExpander
    expander = QueryExpander()
    
    test_queries = [
        "ch·ªâ ti√™u tuy·ªÉn sinh 2025",
        "ƒëi·ªÉm chu·∫©n ng√†nh c√¥ng ngh·ªá th√¥ng tin",
        "h·ªçc ph√≠ ƒë·∫°i h·ªçc qu·ªëc gia",
        "th·ªùi gian n·ªôp h·ªì s∆° tuy·ªÉn sinh"
    ]
    
    for query in test_queries:
        print(f"\n=== Test query: '{query}' ===")
        
        # Test synonyms
        synonyms = expander.expand_with_synonyms(query)
        print(f"Synonyms: {synonyms[:3]}")
        
        # Test keywords
        keywords = expander.extract_keywords(query)
        print(f"Keywords: {keywords}")
        
        # Test context queries
        context = expander.create_context_queries(query)
        print(f"Context: {context[:3]}")
        
        # Test combined expansion
        combined = expander.expand_query(query, "combined")
        print(f"Combined: {combined[:3]}") 